{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D87eg0tcz5V"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIFs9pT4cs2k"
      },
      "outputs": [],
      "source": [
        "# ! pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE48oYTWiYTk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nicEU1GGie4X"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "We import the necessary libraries and modules for our code.\n",
        "We use PyTorch as our deep learning framework, \n",
        "nn module for defining neural networks, \n",
        "optim module for optimization algorithms, \n",
        "and transforms module for data preprocessing.\n",
        "'''\n",
        "# Define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        CNN Architecture: 2 convolutional layers, 1 max pool, 2 fully connected layer, \n",
        "        and final fully connected layer to classify 10 different classes\n",
        "        \"\"\"\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # ((256-5)/1) +1 = 252\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 252 * 252 * 6 -> ((252-2)/2) +1 = 126\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # ((126-5)/1) +1 = 122\n",
        "        self.fc1 = nn.Linear(16 * 61 * 61, 120) # pool : ((122-2)/2) +1 = 61\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the network.\n",
        "        \"\"\"\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 61 * 61)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qn0O3h1iok8",
        "outputId": "73ca4126-b573-4c03-bf83-c687a33b8a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6lGW8Bul7Oq"
      },
      "outputs": [],
      "source": [
        "# from zipfile import ZipFile\n",
        "\n",
        "# with ZipFile(\"/content/drive/MyDrive/SI_flood_dataset.zip\", 'r') as zip:\n",
        "#   zip.extractall(\"/content/drive/MyDrive/SI_flood_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gkqk7ErTfve"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Creates a data transformation pipeline using the transforms.Compose function from the PyTorch library.\n",
        "\n",
        "\"\"\"\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((256, 256)), \n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "# rotate 90 degree\n",
        "transform_augmented_90 = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=90),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "# rotate 180 degree\n",
        "transform_augmented_180 = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=180),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "# rotate 270 degree\n",
        "transform_augmented_270 = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=270),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlyWWTcAj-O6"
      },
      "outputs": [],
      "source": [
        "# import splitfolders\n",
        "# # Load the dataset\n",
        "\n",
        "# splitfolders.ratio('/content/drive/MyDrive/SI_flood_dataset/dataset/classes', # The location of dataset\n",
        "#                    output=\"/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split\", # The output location\n",
        "#                    seed=42, # The number of seed\n",
        "#                    ratio=(.8, .2,), # The ratio of splited dataset\n",
        "#                    group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
        "#                    move=True # If you choose to move, turn this into True\n",
        "#                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NqgkMMpPInxV"
      },
      "outputs": [],
      "source": [
        "\n",
        "augmented_dataSet_train = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/train_eq', transform=transform) \n",
        "augmented_dataSet_test = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/val_eq', transform=transform) \n",
        "\n",
        "\n",
        "augmented_dataSet_train += torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/train_eq', transform=transform_augmented_90) \n",
        "augmented_dataSet_train += torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/train_eq', transform=transform_augmented_180) \n",
        "augmented_dataSet_test += torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/val_eq', transform=transform_augmented_270) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JSPD37y1S8Q0"
      },
      "outputs": [],
      "source": [
        "# Data loaders\n",
        "train_dataset_loader = torch.utils.data.DataLoader(\n",
        "    augmented_dataSet_train, batch_size=4, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_dataset_loader = torch.utils.data.DataLoader(\n",
        "    augmented_dataSet_test, batch_size=4, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oTqgFYEw0bNT"
      },
      "outputs": [],
      "source": [
        "# # Load the saved weights into a new instance of the Net class\n",
        "net = Net()\n",
        "# net.load_state_dict(torch.load('SI_models_CNN_256_weights.pth'))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaEX3aHETJZB",
        "outputId": "5fa52e7f-6b22-4bad-e34a-07b75ae7cd5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Train the network\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataset_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "JusUh0Ca18np"
      },
      "outputs": [],
      "source": [
        "# Save the trained weights to a file\n",
        "torch.save(net.state_dict(), 'SI_models_CNN_eq_augmented_256_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ONdDOb6yDBBI"
      },
      "outputs": [],
      "source": [
        "# # print weights\n",
        "# saved_weights = torch.load('SI_models_CNN_256_weights.pth')\n",
        "# print(saved_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zOfoe2cTQf0",
        "outputId": "d351e8d6-ea95-427f-9102-b1c14a422eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 88 %\n"
          ]
        }
      ],
      "source": [
        "# Test the network on the test data\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_dataset_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGLW4AfecGKu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}