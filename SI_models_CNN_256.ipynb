{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "9D87eg0tcz5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIFs9pT4cs2k",
        "outputId": "dda144b5-8166-42a6-8039-e01ca34161bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "# ! pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "RE48oYTWiYTk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "We import the necessary libraries and modules for our code.\n",
        "We use PyTorch as our deep learning framework, \n",
        "nn module for defining neural networks, \n",
        "optim module for optimization algorithms, \n",
        "and transforms module for data preprocessing.\n",
        "'''\n",
        "# Define the CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        CNN Architecture: 2 convolutional layers, 1 max pool, 2 fully connected layer, \n",
        "        and final fully connected layer to classify 10 different classes\n",
        "        \"\"\"\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # ((256-5)/1) +1 = 252\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 252 * 252 * 6 -> ((252-2)/2) +1 = 126\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # ((126-5)/1) +1 = 122\n",
        "        self.fc1 = nn.Linear(16 * 61 * 61, 120) # pool : ((122-2)/2) +1 = 61\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines the forward pass of the network.\n",
        "        \"\"\"\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 61 * 61)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "nicEU1GGie4X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qn0O3h1iok8",
        "outputId": "3d85512f-3714-43b7-b98c-4cedc55b4f01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from zipfile import ZipFile\n",
        "\n",
        "# with ZipFile(\"/content/drive/MyDrive/SI_flood_dataset.zip\", 'r') as zip:\n",
        "#   zip.extractall(\"/content/drive/MyDrive/SI_flood_dataset\")"
      ],
      "metadata": {
        "id": "m6lGW8Bul7Oq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creates a data transformation pipeline using the transforms.Compose function from the PyTorch library.\n",
        "\n",
        "\"\"\"\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((256, 256)), \n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
      ],
      "metadata": {
        "id": "_gkqk7ErTfve"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "# Load the dataset\n",
        "\n",
        "splitfolders.ratio('/content/drive/MyDrive/SI_flood_dataset/dataset/classes', # The location of dataset\n",
        "                   output=\"/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split\", # The output location\n",
        "                   seed=42, # The number of seed\n",
        "                   ratio=(.8, .2,), # The ratio of splited dataset\n",
        "                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
        "                   move=True # If you choose to move, turn this into True\n",
        "                   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlyWWTcAj-O6",
        "outputId": "9bb3f095-9799-4d43-ac91-75072835c3b9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 0 files [00:00, ? files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataSet = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/train', transform=transform) \n",
        "test_dataSet = torchvision.datasets.ImageFolder(root='/content/drive/MyDrive/SI_flood_dataset/dataset/SI_flood_dataset_split/val', transform=transform) \n"
      ],
      "metadata": {
        "id": "NqgkMMpPInxV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loaders\n",
        "train_dataset_loader = torch.utils.data.DataLoader(\n",
        "    train_dataSet, batch_size=4, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_dataset_loader = torch.utils.data.DataLoader(\n",
        "    test_dataSet, batch_size=4, shuffle=False, num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "JSPD37y1S8Q0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
      ],
      "metadata": {
        "id": "Ovqia03sTE2j"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_dataset_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Test the network on the test data\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in train_dataset_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaEX3aHETJZB",
        "outputId": "b015cc6e-c227-4f03-e3c9-4ddc90140b57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zOfoe2cTQf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}