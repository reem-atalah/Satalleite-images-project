{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset using pandas\n",
    "df = pd.read_excel(\"Concrete_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataframe into a training and testing splits with a 70% / 30% ratio\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42) # Random is fixed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the models input and targets from both the training and testing dataframes\n",
    "def extract_Xy(df):\n",
    "    df_numpy = df.to_numpy()\n",
    "    return df_numpy[:, :-1], df_numpy[:, -1]\n",
    "\n",
    "X_train, y_train = extract_Xy(df_train)\n",
    "X_test, y_test = extract_Xy(df_test)\n",
    "\n",
    "y_median = np.median(y_train)\n",
    "print(\"Median value of the target:\", y_median)\n",
    "\n",
    "# Since we will treat this as a classification task, we will assume that\n",
    "# the concrete is \"strong\" (y = True) if its compressive ratio is higher than the median\n",
    "# otherwise, it is assumed to be \"weak\" (y = False)\n",
    "y_train = y_train > y_median\n",
    "y_test = y_test > y_median\n",
    "\n",
    "# Now ~50% of the samples should be considered \"strong\" and the rest are considered \"weak\"\n",
    "print(f\"Percentage of 'strong' samples: {y_train.mean() * 100} %\")\n",
    "\n",
    "# Also, lets standardize the data since it improves the training process\n",
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train = (X_train - X_mean)/(1e-8 + X_std)\n",
    "X_test = (X_test - X_mean)/(1e-8 + X_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericBagging:\n",
    "\n",
    "    def __init__(self, n_estimators):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.estimators = []\n",
    "        self.initialize_estimators()\n",
    "        \n",
    "    def initialize_estimators(self):\n",
    "        # initialize the given number of estimators\n",
    "        for _ in self.n_estimators:\n",
    "            # Don't change the decision tree parameters\n",
    "            self.estimators.append(DecisionTreeClassifier(max_depth=5, random_state=0))\n",
    "\n",
    "    def generate_data_subset(self):\n",
    "        # TODO: Generate bootstrap samples (with replacement)\n",
    "        # Use a subset size of 300 samples\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # TODO: loop over each classifier and fit on random data subset\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        # TODO: implement prediction function using majority vote\n",
    "        pass\n",
    "    \n",
    "    def calculate_oob_error(self, X, Y):\n",
    "        # TODO: calculate Out-of-Bag error\n",
    "        # The out-of-bag (OOB) error is the average error for each training observation\n",
    "        # calculated using predictions from the trees that do not contain this training observation\n",
    "        # in their respective bootstrap sample. \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(n_estimators):\n",
    "    # run model bagging and compute OOB error and test accuracy\n",
    "    model = GenericBagging(n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    return model.calculate_oob_error(X_train, y_train), accuracy_score(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bagging():\n",
    "    n_estimators_options = [5, 10, 50, 100, 200, 500]\n",
    "    oob_errors = []\n",
    "    test_accuracies = []\n",
    "    for n_estimators in n_estimators_options:\n",
    "        oob_error, test_accuracy = get_scores(n_estimators)\n",
    "        oob_errors.append(oob_error)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    # TODO: plot the output scores against n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_bagging()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericBoosting:\n",
    "\n",
    "    def __init__(self, n_estimators):\n",
    "        self.n_estimators = n_estimators\n",
    "\n",
    "    def create_estimator(self):\n",
    "        # create a decision stump as a weak estimator\n",
    "        return DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "\n",
    "    def fit_and_predict(self, X_train, Y_train, X_test, Y_test):\n",
    "        # apply AdaBoost on weak estimators\n",
    "        \n",
    "        ## initialize the training and test data with empty array placeholders\n",
    "        pred_train = np.empty((self.n_estimators, X_train.shape[0]))\n",
    "        pred_test = np.empty((self.n_estimators, X_test.shape[0]))\n",
    "        \n",
    "        # initialize weights\n",
    "        W = np.ones((X_train.shape[0],)) / X_train.shape[0]\n",
    "\n",
    "        # loop over the boosting iterations \n",
    "        for idx in range(self.n_estimators): \n",
    "\n",
    "            # create and fit a new decision stump\n",
    "            model = self.create_estimator().fit(X_train, Y_train, sample_weight=W)\n",
    "\n",
    "            # predict classes for the training data and test data\n",
    "            pred_train_idx = model.predict(X_train)\n",
    "            pred_test_idx = model.predict(X_test)\n",
    "\n",
    "            # TODO: calculate the miss Indicator\n",
    "            miss_indicator = None\n",
    "\n",
    "            # TODO: calculate the error for the current classifier\n",
    "            cls_err =  None\n",
    "\n",
    "            # TODO: calculate current classifier weight\n",
    "            cls_alpha = None\n",
    "\n",
    "            # TODO: update the weights \n",
    "            W = None\n",
    "\n",
    "            # TODO: add to the overall predictions\n",
    "            pred_train[idx] = None\n",
    "            pred_test[idx] = None\n",
    "\n",
    "            # normalize weights \n",
    "            W = W / np.sum(W)\n",
    "\n",
    "        # TODO: return accuracy on train and test sets\n",
    "        train_accuracy = None\n",
    "        test_accuracy = None\n",
    "        \n",
    "        return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(n_estimators):\n",
    "    # run model boosting and compute train and test accuracy\n",
    "    model = GenericBoosting(n_estimators=n_estimators)\n",
    "    train_accuracy, test_accuracy = model.fit_and_predict(X_train, y_train, X_test, y_test)\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_boosting():\n",
    "    n_estimators_options = [5, 10, 50, 100, 200, 500]\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for n_estimators in n_estimators_options:\n",
    "        train_accuracy, test_accuracy = get_scores(n_estimators)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    # TODO: plot the output scores against n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_boosting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd780a10ad03a506e232ec29f104692e8d999a77309c0fc915217df500c72051"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
